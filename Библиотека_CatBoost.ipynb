{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoDc44y1NyYnDWY6yCEUdD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/A_PythonLibraries/blob/main/%D0%91%D0%B8%D0%B1%D0%BB%D0%B8%D0%BE%D1%82%D0%B5%D0%BA%D0%B0_CatBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Библиотека CatBoost для задач классификации\n",
        "\n",
        "## Введение\n",
        "\n",
        "CatBoost (Categorical Boosting) — это библиотека для градиентного бустинга, разработанная Яндексом. Она предназначена для работы с категориальными данными и обеспечивает высокую производительность при обработке больших наборов данных. В этой лекции мы подробно рассмотрим, как использовать CatBoost для решения задач классификации и регрессии, включая теоретические основы, функции потерь, метрики оценки, примеры использования и лучшие практики.\n",
        "\n",
        "## 1. Основные понятия\n",
        "\n",
        "### 1.1. Градиентный бустинг\n",
        "\n",
        "Градиентный бустинг — это метод ансамблевого обучения, который строит модель, последовательно обучая слабые модели (обычно деревья решений) и корректируя ошибки предыдущих. Каждое новое дерево обучается на градиенте функции потерь от предсказаний предыдущих деревьев.\n",
        "\n",
        "Формально, предсказание $F(x)$ для объекта $x$ можно выразить как:\n",
        "\n",
        "$$\n",
        "F(x) = F_{m-1}(x) + \\nu \\cdot h_m(x)\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $F_{m-1}(x)$ — предсказание предыдущей модели,\n",
        "- $\\nu$ — скорость обучения,\n",
        "- $h_m(x)$ — m-ое дерево решений.\n",
        "\n",
        "### 1.2. Потери для задач классификации\n",
        "\n",
        "Для задач классификации используются различные функции потерь в зависимости от типа задачи:\n",
        "\n",
        "- **Бинарная классификация:** логистическая регрессия. Функция потерь:\n",
        "\n",
        "$$\n",
        "L(y, F(x)) = - \\left( y \\log(\\sigma(F(x))) + (1 - y) \\log(1 - \\sigma(F(x))) \\right)\n",
        "$$\n",
        "\n",
        "где $\\sigma$ — логистическая функция.\n",
        "\n",
        "- **Мультиклассовая классификация:** кросс-энтропия. Функция потерь:\n",
        "\n",
        "$$\n",
        "L(y, F(x)) = - \\sum_{c=1}^{C} y_c \\log(\\sigma(F_c(x)))\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $C$ — количество классов,\n",
        "- $y_c$ — бинарный индикатор (1 или 0) для класса $c$,\n",
        "- $\\sigma(F_c(x))$ — вероятность того, что объект принадлежит классу $c$.\n",
        "\n",
        "## 2. Установка и подготовка к работе с CatBoost\n",
        "\n",
        "Для начала необходимо установить библиотеку. Это можно сделать с помощью pip:\n",
        "\n",
        "```bash\n",
        "pip install catboost\n",
        "```\n",
        "\n",
        "Импортируем необходимые библиотеки:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "```\n",
        "\n",
        "## 3. Пример 1: Бинарная классификация\n",
        "\n",
        "### 3.1. Подготовка данных\n",
        "\n",
        "Рассмотрим набор данных \"Titanic\", в котором мы будем предсказывать выживание пассажиров.\n",
        "\n",
        "```python\n",
        "# Загрузка данных\n",
        "data = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Выбор необходимых столбцов\n",
        "data = data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
        "\n",
        "# Обработка пропусков\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "\n",
        "# Кодирование категориальных признаков\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X = data.drop('Survived', axis=1)\n",
        "y = data['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### 3.2. Обучение модели\n",
        "\n",
        "Создаем и обучаем модель CatBoost:\n",
        "\n",
        "```python\n",
        "model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, verbose=100)\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### 3.3. Оценка модели\n",
        "\n",
        "Теперь оценим качество модели:\n",
        "\n",
        "```python\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "```\n",
        "\n",
        "### 3.4. Важность признаков\n",
        "\n",
        "CatBoost позволяет легко визуализировать важность признаков:\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "feature_importances = model.get_feature_importance()\n",
        "plt.barh(X.columns, feature_importances)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "## 4. Пример 2: Мультиклассовая классификация\n",
        "\n",
        "Рассмотрим набор данных \"Iris\", в котором мы будем предсказывать вид цветка.\n",
        "\n",
        "### 4.1. Подготовка данных\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Загрузка данных\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### 4.2. Обучение модели\n",
        "\n",
        "```python\n",
        "model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, verbose=100)\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### 4.3. Оценка модели\n",
        "\n",
        "```python\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_test, y_pred))\n",
        "```\n",
        "\n",
        "### 4.4. Важность признаков\n",
        "\n",
        "```python\n",
        "feature_importances = model.get_feature_importance()\n",
        "plt.barh(iris.feature_names, feature_importances)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "## 5. Метрики для оценки качества классификации\n",
        "\n",
        "### 5.1. Accuracy\n",
        "\n",
        "Accuracy (доля правильных предсказаний) определяется как:\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $TP$ — истинно положительные,\n",
        "- $TN$ — истинно отрицательные,\n",
        "- $FP$ — ложно положительные,\n",
        "- $FN$ — ложно отрицательные.\n",
        "\n",
        "### 5.2. Precision и Recall\n",
        "\n",
        "- **Precision (точность)**:\n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "- **Recall (полнота)**:\n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "### 5.3. F1-score\n",
        "\n",
        "F1-score — гармоническое среднее точности и полноты:\n",
        "\n",
        "$$\n",
        "F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "### 5.4. ROC и AUC\n",
        "\n",
        "- **ROC (Receiver Operating Characteristic)** — кривая, показывающая соотношение между чувствительностью (Recall) и специфичностью (1 - FPR).\n",
        "- **AUC (Area Under the Curve)** — площадь под кривой ROC. Чем выше AUC, тем лучше модель.\n",
        "\n",
        "## 6. Обработка категориальных признаков\n",
        "\n",
        "CatBoost может обрабатывать категориальные данные без необходимости их предварительного кодирования, что позволяет избежать переобучения и потери информации.\n",
        "\n",
        "### Пример обработки категориальных признаков\n",
        "\n",
        "```python\n",
        "# Пример данных\n",
        "data = pd.DataFrame({\n",
        "    'Category': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B'],\n",
        "    'Value': [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "    'Target': [0, 1, 0, 1, 0, 1, 0, 1]\n",
        "})\n",
        "\n",
        "# Определяем категориальные признаки\n",
        "cat_features = ['Category']\n",
        "\n",
        "# Разделяем данные\n",
        "X = data.drop('Target', axis=1)\n",
        "y = data['Target']\n",
        "\n",
        "# Создаем и обучаем модель\n",
        "model = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=3, cat_features=cat_features, verbose=10)\n",
        "model.fit(X, y)\n",
        "```\n",
        "\n",
        "## 7. Настройка гиперпараметров\n",
        "\n",
        "### Пример настройки гиперпараметров с GridSearchCV\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'iterations': [100, 200],\n",
        "    'depth': [3, 6],\n",
        "    'learning_rate': [0.1, 0.01],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=CatBoostClassifier(cat_features=cat_features, verbose=0),\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=3)\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
        "```\n",
        "\n",
        "## 8. Кросс-валидация\n",
        "\n",
        "### Пример кросс-валидации\n",
        "\n",
        "```python\n",
        "from catboost import cv, Pool\n",
        "\n",
        "# Создаем Pool для кросс-валидации\n",
        "\n",
        "\n",
        "pool = Pool(X, y, cat_features=cat_features)\n",
        "\n",
        "# Параметры кросс-валидации\n",
        "params = {\n",
        "    'iterations': 100,\n",
        "    'learning_rate': 0.1,\n",
        "    'depth': 3,\n",
        "    'eval_metric': 'Accuracy'\n",
        "}\n",
        "\n",
        "# Выполняем кросс-валидацию\n",
        "cv_results = cv(params, pool, fold_count=5, shuffle=True, plot=True)\n",
        "```\n",
        "\n",
        "\n",
        "Давайте рассмотрим конкретные примеры использования библиотеки CatBoost для задач классификации, включая подготовку данных, обучение модели, оценку качества и визуализацию результатов.\n",
        "\n",
        "## Пример 1: Бинарная классификация на основе данных о пассажирах \"Титаника\"\n",
        "\n",
        "### 1. Подготовка данных\n",
        "\n",
        "Сначала загрузим данные и проведем их предобработку. Мы будем использовать набор данных \"Titanic\", который доступен в Kaggle или других источниках.\n",
        "\n",
        "#### Шаг 1: Загрузка необходимых библиотек\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "```\n",
        "\n",
        "#### Шаг 2: Загрузка и предобработка данных\n",
        "\n",
        "```python\n",
        "# Загрузка данных\n",
        "data = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Выбор необходимых столбцов\n",
        "data = data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
        "\n",
        "# Обработка пропусков\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "\n",
        "# Кодирование категориальных признаков\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X = data.drop('Survived', axis=1)\n",
        "y = data['Survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.head())\n",
        "```\n",
        "\n",
        "### 2. Обучение модели\n",
        "\n",
        "#### Шаг 3: Создание и обучение модели\n",
        "\n",
        "```python\n",
        "# Создаем и обучаем модель\n",
        "model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, verbose=100)\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### 3. Оценка качества модели\n",
        "\n",
        "#### Шаг 4: Прогнозирование и оценка\n",
        "\n",
        "```python\n",
        "# Прогнозируем значения\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка качества\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Отчет по классификации\n",
        "print(classification_report(y_test, y_pred))\n",
        "```\n",
        "\n",
        "### 4. Визуализация важности признаков\n",
        "\n",
        "#### Шаг 5: Визуализация важности\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Получаем важность признаков\n",
        "feature_importances = model.get_feature_importance()\n",
        "\n",
        "# Строим график важности признаков\n",
        "plt.barh(X.columns, feature_importances)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "## Пример 2: Мультиклассовая классификация на основе данных о цветах \"Iris\"\n",
        "\n",
        "### 1. Подготовка данных\n",
        "\n",
        "Здесь мы используем набор данных Iris для предсказания вида цветка.\n",
        "\n",
        "#### Шаг 1: Загрузка необходимых библиотек\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "```\n",
        "\n",
        "#### Шаг 2: Загрузка и подготовка данных\n",
        "\n",
        "```python\n",
        "# Загрузка данных\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### 2. Обучение модели\n",
        "\n",
        "#### Шаг 3: Создание и обучение модели\n",
        "\n",
        "```python\n",
        "# Создаем и обучаем модель\n",
        "model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=6, verbose=100)\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### 3. Оценка качества модели\n",
        "\n",
        "#### Шаг 4: Прогнозирование и оценка\n",
        "\n",
        "```python\n",
        "# Прогнозируем значения\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка качества\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Отчет по классификации\n",
        "print(classification_report(y_test, y_pred))\n",
        "```\n",
        "\n",
        "### 4. Визуализация важности признаков\n",
        "\n",
        "#### Шаг 5: Визуализация важности\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Получаем важность признаков\n",
        "feature_importances = model.get_feature_importance()\n",
        "\n",
        "# Строим график важности признаков\n",
        "plt.barh(iris.feature_names, feature_importances)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "## Пример 3: Классификация клиентов в банке\n",
        "\n",
        "В этом примере мы будем предсказывать, уйдет ли клиент из банка, используя вымышленные данные о клиентах.\n",
        "\n",
        "### 1. Подготовка данных\n",
        "\n",
        "#### Шаг 1: Загрузка необходимых библиотек\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "```\n",
        "\n",
        "#### Шаг 2: Создание вымышленного набора данных\n",
        "\n",
        "```python\n",
        "# Создаем вымышленный набор данных\n",
        "data = pd.DataFrame({\n",
        "    'CustomerID': range(1, 101),\n",
        "    'Age': [25, 30, 35, 40, 45] * 20,\n",
        "    'Gender': ['Male', 'Female'] * 50,\n",
        "    'Region': ['North', 'South', 'East', 'West'] * 25,\n",
        "    'Churn': [0, 1, 0, 1, 0] * 20\n",
        "})\n",
        "\n",
        "# Кодируем категориальные признаки\n",
        "data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})\n",
        "data['Region'] = data['Region'].astype('category')\n",
        "\n",
        "# Разделяем данные\n",
        "X = data.drop(['CustomerID', 'Churn'], axis=1)\n",
        "y = data['Churn']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### 2. Обучение модели\n",
        "\n",
        "#### Шаг 3: Создание и обучение модели\n",
        "\n",
        "```python\n",
        "# Создаем и обучаем модель\n",
        "cat_features = ['Region']\n",
        "model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=4, cat_features=cat_features, verbose=100)\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### 3. Оценка качества модели\n",
        "\n",
        "#### Шаг 4: Прогнозирование и оценка\n",
        "\n",
        "```python\n",
        "# Прогнозируем значения\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка качества\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Отчет по классификации\n",
        "print(classification_report(y_test, y_pred))\n",
        "```\n",
        "\n",
        "### 4. Визуализация важности признаков\n",
        "\n",
        "#### Шаг 5: Визуализация важности\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Получаем важность признаков\n",
        "feature_importances = model.get_feature_importance()\n",
        "\n",
        "# Строим график важности признаков\n",
        "plt.barh(X.columns, feature_importances)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "\n",
        "Таким образом, мы рассмотрели основные аспекты работы с библиотекой CatBoost для задач классификации. Мы изучили:\n",
        "\n",
        "- Теоретические основы градиентного бустинга и функции потерь для классификации.\n",
        "- Как установить и подготовить библиотеку CatBoost.\n",
        "- Примеры бинарной и мультиклассовой классификации.\n",
        "- Важность признаков и метрики для оценки качества модели.\n",
        "- Обработку категориальных признаков, настройку гиперпараметров и кросс-валидацию.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lGx_jPeIIMbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Библиотека CatBoost для задач регрессии\n",
        "\n",
        "\n",
        "## 1. Основные понятия\n",
        "\n",
        "###  Потери для задач регрессии\n",
        "\n",
        "Для задач регрессии используются различные функции потерь в зависимости от задачи:\n",
        "\n",
        "- **Среднеквадратичная ошибка (MSE)**. Функция потерь:\n",
        "\n",
        "$$\n",
        "L(y, F(x)) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - F(x_i))^2\n",
        "$$\n",
        "\n",
        "где $y$ — истинные значения, $F(x)$ — предсказанные значения.\n",
        "\n",
        "- **Средняя абсолютная ошибка (MAE)**. Функция потерь:\n",
        "\n",
        "$$\n",
        "L(y, F(x)) = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - F(x_i)|\n",
        "$$\n",
        "\n",
        "## 2. Установка и подготовка к работе с CatBoost\n",
        "\n",
        "Для начала необходимо установить библиотеку. Это можно сделать с помощью pip:\n",
        "\n",
        "```bash\n",
        "pip install catboost\n",
        "```\n",
        "\n",
        "Импортируем необходимые библиотеки:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "```\n",
        "\n",
        "## 3. Пример 1: Регрессия\n",
        "\n",
        "### 3.1. Подготовка данных\n",
        "\n",
        "Рассмотрим набор данных \"California housing\", в котором мы будем предсказывать среднюю цену жилья.\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Загрузка данных\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### 3.2. Обучение модели\n",
        "\n",
        "Создаем и обучаем модель CatBoost:\n",
        "\n",
        "```python\n",
        "model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, verbose=100)\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### 3.3. Оценка модели\n",
        "\n",
        "Теперь оценим качество модели:\n",
        "\n",
        "```python\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae:.2f}')\n",
        "```\n",
        "\n",
        "### 3.4. Важность признаков\n",
        "\n",
        "CatBoost позволяет легко визуализировать важность признаков:\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "feature_importances = model.get_feature_importance()\n",
        "plt.barh(X.columns, feature_importances)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "## 4. Метрики для оценки качества регрессии\n",
        "\n",
        "### 4.1. Среднеквадратичная ошибка (MSE)\n",
        "\n",
        "Среднеквадратичная ошибка (MSE) определяется как:\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $y_i$ — истинные значения,\n",
        "- $\\hat{y}_i$ — предсказанные значения.\n",
        "\n",
        "### 4.2. Средняя абсолютная ошибка (MAE)\n",
        "\n",
        "Средняя абсолютная ошибка (MAE) определяется как:\n",
        "\n",
        "$$\n",
        "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
        "$$\n",
        "\n",
        "## 5. Обработка категориальных признаков\n",
        "\n",
        "CatBoost может обрабатывать категориальные данные без необходимости их предварительного кодирования, что позволяет избежать переобучения и потери информации.\n",
        "\n",
        "### Пример обработки категориальных признаков\n",
        "\n",
        "```python\n",
        "# Пример данных\n",
        "data = pd.DataFrame({\n",
        "    'Category': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B'],\n",
        "    'Value': [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "    'Target': [0.5, 1.0, 0.6, 1.5, 0.9, 1.2, 0.7, 1.0]\n",
        "})\n",
        "\n",
        "# Определяем категориальные признаки\n",
        "cat_features = ['Category']\n",
        "\n",
        "# Разделяем данные\n",
        "X = data.drop('Target', axis=1)\n",
        "y = data['Target']\n",
        "\n",
        "# Создаем и обучаем модель\n",
        "model = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=3, cat_features=cat_features, verbose=10)\n",
        "model.fit(X, y)\n",
        "```\n",
        "\n",
        "## 6. Настройка гиперпараметров\n",
        "\n",
        "### Пример настройки гиперпараметров с GridSearchCV\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'iterations': [100, 200],\n",
        "    'depth': [3, 6],\n",
        "    'learning_rate': [0.1, 0.01],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=CatBoostRegressor(cat_features=cat_features, verbose=0),\n",
        "                           param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           cv=3)\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
        "```\n",
        "\n",
        "## 7. Кросс-валидация\n",
        "\n",
        "### Пример кросс-валидации\n",
        "\n",
        "```python\n",
        "from catboost import cv, Pool\n",
        "\n",
        "# Создаем Pool для кросс-валидации\n",
        "pool = Pool(X, y, cat_features=cat_features)\n",
        "\n",
        "# Параметры кросс-валидации\n",
        "params = {\n",
        "    'iterations': 100,\n",
        "    'learning_rate': 0.1,\n",
        "    'depth': 3,\n",
        "    'eval_metric': 'RMSE'\n",
        "}\n",
        "\n",
        "# Выполняем кросс-валидацию\n",
        "cv_results = cv(params, pool, fold_count=5, shuffle=True, plot=True)\n",
        "```\n",
        "\n",
        " Давайте разберем несколько конкретных примеров использования CatBoost для решения задач регрессии. Мы будем использовать набор данных \"California housing\", где предсказывается средняя цена жилья, а также рассмотрим набор данных с вымышленными данными для демонстрации обработки категориальных признаков.\n",
        "\n",
        "## Пример 1: Регрессия на наборе данных California Housing\n",
        "\n",
        "### 1. Подготовка данных\n",
        "\n",
        "Загрузим данные, разделим их на обучающую и тестовую выборки, и проведем предварительную обработку.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Загрузка данных\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Проверка размеров выборок\n",
        "print(f'Размер обучающей выборки: {X_train.shape[0]}')\n",
        "print(f'Размер тестовой выборки: {X_test.shape[0]}')\n",
        "```\n",
        "\n",
        "### 2. Обучение модели\n",
        "\n",
        "Создадим и обучим модель CatBoostRegressor.\n",
        "\n",
        "```python\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Создаем и обучаем модель\n",
        "model = CatBoostRegressor(iterations=1000, learning_rate=0.1, depth=6, verbose=100)\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### 3. Оценка модели\n",
        "\n",
        "Оценим качество модели с помощью среднеквадратичной ошибки (MSE) и средней абсолютной ошибки (MAE).\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Предсказания на тестовой выборке\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae:.2f}')\n",
        "```\n",
        "\n",
        "### 4. Важность признаков\n",
        "\n",
        "Визуализируем важность признаков для нашей модели.\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Получаем важность признаков\n",
        "feature_importances = model.get_feature_importance()\n",
        "plt.barh(X.columns, feature_importances)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "## Пример 2: Регрессия с категориальными признаками\n",
        "\n",
        "Для этого примера создадим набор данных с вымышленными данными, включая категориальные признаки.\n",
        "\n",
        "### 1. Подготовка данных\n",
        "\n",
        "Создадим DataFrame с категориальными и числовыми признаками.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Создаем набор данных\n",
        "data = pd.DataFrame({\n",
        "    'Category': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B', 'A', 'C'],\n",
        "    'Value': np.random.rand(10) * 10,\n",
        "    'Target': np.random.rand(10) * 100\n",
        "})\n",
        "\n",
        "# Проверяем данные\n",
        "print(data)\n",
        "```\n",
        "\n",
        "### 2. Обработка категориальных признаков\n",
        "\n",
        "Определяем категориальные признаки и разделяем данные на обучающую и тестовую выборки.\n",
        "\n",
        "```python\n",
        "# Определяем категориальные признаки\n",
        "cat_features = ['Category']\n",
        "\n",
        "# Разделяем данные\n",
        "X = data.drop('Target', axis=1)\n",
        "y = data['Target']\n",
        "\n",
        "# Разделяем на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "\n",
        "### 3. Обучение модели\n",
        "\n",
        "Обучаем модель, указывая, какие признаки являются категориальными.\n",
        "\n",
        "```python\n",
        "# Создаем и обучаем модель\n",
        "model = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=3, cat_features=cat_features, verbose=10)\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### 4. Оценка модели\n",
        "\n",
        "Оцениваем качество модели, как и в предыдущем примере.\n",
        "\n",
        "```python\n",
        "# Предсказания на тестовой выборке\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae:.2f}')\n",
        "```\n",
        "\n",
        "### 5. Важность признаков\n",
        "\n",
        "Визуализируем важность признаков для модели с категориальными данными.\n",
        "\n",
        "```python\n",
        "# Получаем важность признаков\n",
        "feature_importances = model.get_feature_importance()\n",
        "plt.barh(X.columns, feature_importances)\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Таким образом, мы рассмотрели основные аспекты работы с библиотекой CatBoost для задач регрессии. Мы изучили:\n",
        "\n",
        "- Теоретические основы градиентного бустинга и функции потерь для регрессии.\n",
        "- Как установить и подготовить библиотеку CatBoost.\n",
        "- Примеры регрессии на наборе данных California housing.\n",
        "- Важность признаков и метрики для оценки качества модели.\n",
        "- Обработку категориальных признаков, настройку гиперпараметров и кросс-валидацию.\n"
      ],
      "metadata": {
        "id": "1LlQTpINWM7e"
      }
    }
  ]
}