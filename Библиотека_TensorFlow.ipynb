{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx4QqAqxpzXTjDU5czLXvc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/A_PythonLibraries/blob/main/%D0%91%D0%B8%D0%B1%D0%BB%D0%B8%D0%BE%D1%82%D0%B5%D0%BA%D0%B0_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Библиотека TensorFlow\n",
        "\n",
        "#### Введение в TensorFlow\n",
        "\n",
        "**TensorFlow** — это одна из самых популярных библиотек для разработки и применения моделей машинного обучения и нейронных сетей. Она была разработана компанией Google и активно используется в проектах, связанных с глубоким обучением, обработкой изображений, текстов и другими задачами искусственного интеллекта.\n",
        "\n",
        "TensorFlow изначально был разработан для масштабируемых вычислений и может работать как на единичных устройствах (CPU/GPU), так и в распределенных системах с большим количеством узлов. Он поддерживает автоматическую дифференцировку, что является важной особенностью для обучения нейронных сетей через метод обратного распространения ошибки (backpropagation).\n",
        "\n",
        "#### Основные компоненты TensorFlow:\n",
        "\n",
        "- **Граф вычислений (Computational Graph)**: TensorFlow работает на основе построения графа вычислений, где узлы представляют собой операции (функции), а рёбра — данные (тензоры).\n",
        "  \n",
        "- **Тензоры (Tensors)**: Это основная структура данных TensorFlow. Тензоры представляют собой многомерные массивы данных.\n",
        "\n",
        "- **Сессии (Sessions)**: Ранее в TensorFlow 1.x сессии использовались для выполнения вычислений в графе. Однако в TensorFlow 2.x сессии были заменены на более простую парадигму, где выполнение происходит \"сразу\" (eager execution).\n",
        "\n",
        "- **Keras**: TensorFlow включает в себя высокоуровневое API Keras для создания и обучения моделей машинного обучения.\n",
        "\n",
        "#### Установка TensorFlow\n",
        "\n",
        "Чтобы начать работу с TensorFlow, его необходимо установить. Это можно сделать через pip:\n",
        "\n",
        "```bash\n",
        "pip install tensorflow\n",
        "```\n",
        "\n",
        "Теперь перейдём к теоретическим аспектам и практике.\n",
        "\n",
        "\n",
        "\n",
        "### Основы TensorFlow\n",
        "\n",
        "#### Тензоры\n",
        "\n",
        "Тензор — это многомерный массив данных, аналогичный массивам NumPy, но с возможностью обработки на GPU.\n",
        "\n",
        "Пример создания простого тензора в TensorFlow:\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "# Создадим константный тензор\n",
        "tensor = tf.constant([[1, 2], [3, 4]])\n",
        "\n",
        "print(tensor)\n",
        "```\n",
        "\n",
        "Здесь мы создали двухмерный тензор. Этот тензор является объектом класса `tf.Tensor`, который может содержать данные различных типов.\n",
        "\n",
        "**Типы тензоров**:\n",
        "\n",
        "1. **Константы (tf.constant)** — неизменяемые тензоры.\n",
        "2. **Переменные (tf.Variable)** — изменяемые тензоры, которые используются при обучении моделей.\n",
        "3. **Массивы из Python/NumPy** — можно легко преобразовать массивы NumPy в тензоры.\n",
        "\n",
        "Пример переменной:\n",
        "\n",
        "```python\n",
        "variable = tf.Variable([[1.0, 2.0], [3.0, 4.0]])\n",
        "print(variable)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "#### Автоматическая дифференциация\n",
        "\n",
        "Один из ключевых моментов TensorFlow — это автоматическая дифференциация. Для машинного обучения это важно, поскольку градиенты используются в алгоритмах оптимизации.\n",
        "\n",
        "Пример вычисления градиента функции:\n",
        "\n",
        "```python\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "# Функция, от которой будем искать производную\n",
        "with tf.GradientTape() as tape:\n",
        "    y = x**2\n",
        "\n",
        "# Получим производную y по x\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(dy_dx)  # Ожидаем 6.0\n",
        "```\n",
        "\n",
        "Здесь мы использовали объект `GradientTape`, который \"записывает\" вычисления, чтобы затем можно было вычислить производные по переменным.\n",
        "\n",
        "\n",
        "\n",
        "### Построение моделей с Keras\n",
        "\n",
        "Одной из ключевых особенностей TensorFlow 2.x является интеграция с **Keras** — высокоуровневым API для создания моделей машинного обучения.\n",
        "\n",
        "#### Пример: Простая полносвязная модель нейронной сети\n",
        "\n",
        "Ниже приведен пример простой полносвязной модели для задачи классификации. Мы используем встроенный датасет MNIST для распознавания рукописных цифр.\n",
        "\n",
        "1. **Импорт библиотек и данных:**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Загрузим датасет MNIST\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Нормализуем данные\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "```\n",
        "\n",
        "Датасет MNIST состоит из изображений цифр 28x28 в оттенках серого. Мы нормализовали данные, чтобы значения пикселей были в диапазоне от 0 до 1.\n",
        "\n",
        "2. **Создание модели:**\n",
        "\n",
        "```python\n",
        "# Построим модель\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),  # Преобразуем 28x28 изображения в одномерный вектор\n",
        "    layers.Dense(128, activation='relu'),  # Полносвязный слой с 128 нейронами и активацией ReLU\n",
        "    layers.Dropout(0.2),                   # Dropout для регуляризации\n",
        "    layers.Dense(10)                       # Выходной слой для 10 классов (цифры от 0 до 9)\n",
        "])\n",
        "```\n",
        "\n",
        "Модель состоит из трёх слоев:\n",
        "- **Flatten**: преобразует двумерные изображения в одномерный вектор.\n",
        "- **Dense**: стандартный полносвязный слой нейронов.\n",
        "- **Dropout**: техника регуляризации для предотвращения переобучения.\n",
        "\n",
        "3. **Компиляция модели:**\n",
        "\n",
        "```python\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "Здесь мы используем оптимизатор Adam и функцию потерь `SparseCategoricalCrossentropy`, которая подходит для задачи классификации с несколькими классами. Метрика — точность (`accuracy`).\n",
        "\n",
        "4. **Обучение модели:**\n",
        "\n",
        "```python\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "```\n",
        "\n",
        "Мы обучаем модель на тренировочных данных в течение 5 эпох. На каждой эпохе модель обновляет свои параметры.\n",
        "\n",
        "5. **Оценка модели:**\n",
        "\n",
        "```python\n",
        "model.evaluate(x_test, y_test)\n",
        "```\n",
        "\n",
        "Эта команда оценивает модель на тестовых данных, предоставляя информацию о точности.\n",
        "\n",
        "6. **Прогнозирование:**\n",
        "\n",
        "```python\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Выведем предсказание для первого тестового изображения\n",
        "print(tf.argmax(predictions[0]))\n",
        "```\n",
        "\n",
        "Прогнозирование осуществляется для каждого изображения. `tf.argmax` возвращает индекс с наибольшей вероятностью, то есть цифру, которую модель считает наиболее вероятной.\n",
        "\n",
        "\n",
        "\n",
        "### Возможности TensorFlow\n",
        "\n",
        "TensorFlow поддерживает множество продвинутых возможностей, таких как обучение на GPU, работа с распределенными системами, создание и обучение сложных нейронных сетей.\n",
        "\n",
        "#### Пример: Использование GPU\n",
        "\n",
        "TensorFlow автоматически использует доступный GPU, если он установлен и поддерживается. Однако иногда важно явно указать устройство для выполнения вычислений.\n",
        "\n",
        "```python\n",
        "with tf.device('/GPU:0'):\n",
        "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
        "    b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
        "    c = tf.matmul(a, b)\n",
        "\n",
        "print(c)\n",
        "```\n",
        "\n",
        "Если у вас есть поддерживаемая GPU, этот код выполнится на ней. Чтобы посмотреть, какие устройства доступны TensorFlow:\n",
        "\n",
        "```python\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "```\n",
        "\n",
        "#### Сохранение и загрузка моделей\n",
        "\n",
        "После того как вы обучили модель, её можно сохранить для дальнейшего использования или передачи.\n",
        "\n",
        "1. **Сохранение модели:**\n",
        "\n",
        "```python\n",
        "model.save('my_model.h5')\n",
        "```\n",
        "\n",
        "2. **Загрузка модели:**\n",
        "\n",
        "```python\n",
        "new_model = tf.keras.models.load_model('my_model.h5')\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### TensorFlow и обработка данных\n",
        "\n",
        "TensorFlow предоставляет мощные инструменты для работы с данными. Один из таких инструментов — это `tf.data`, который позволяет работать с потоками данных.\n",
        "\n",
        "Пример создания потока данных:\n",
        "\n",
        "```python\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "\n",
        "# Применим трансформации к датасету\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
        "```\n",
        "\n",
        "Здесь мы создаём поток данных из тренировочных изображений и меток, перемешиваем его и разбиваем на батчи размером 64.\n",
        "\n",
        "\n",
        "\n",
        "### Расширенные возможности TensorFlow\n",
        "\n",
        "#### 1. Создание сложных моделей\n",
        "\n",
        "TensorFlow позволяет создавать сложные архитектуры моделей, такие как сверточные нейронные сети (CNN) и рекуррентные нейронные сети (RNN).\n",
        "\n",
        "##### Пример: Сверточная нейронная сеть (CNN)\n",
        "\n",
        "Сверточные сети особенно эффективны для обработки изображений. Давайте создадим простую CNN для классификации изображений из набора CIFAR-10.\n",
        "\n",
        "1. **Импорт необходимых библиотек и загрузка данных:**\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Загружаем данные\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Нормализация данных\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "```\n",
        "\n",
        "2. **Создание модели CNN:**\n",
        "\n",
        "```python\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)  # 10 классов\n",
        "])\n",
        "```\n",
        "\n",
        "3. **Компиляция и обучение модели:**\n",
        "\n",
        "```python\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "```\n",
        "\n",
        "4. **Оценка модели:**\n",
        "\n",
        "```python\n",
        "model.evaluate(x_test, y_test)\n",
        "```\n",
        "\n",
        "##### 2. Рекуррентные нейронные сети (RNN)\n",
        "\n",
        "RNN используются для работы с последовательными данными, такими как текст или временные ряды. Рассмотрим пример простой RNN для анализа текстовых данных.\n",
        "\n",
        "1. **Подготовка данных:**\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# Загружаем набор данных IMDB\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Паддинг последовательностей\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(x_train, maxlen=500)\n",
        "x_test = pad_sequences(x_test, maxlen=500)\n",
        "```\n",
        "\n",
        "2. **Создание модели RNN:**\n",
        "\n",
        "```python\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(input_dim=10000, output_dim=128, input_length=500),\n",
        "    layers.SimpleRNN(128),\n",
        "    layers.Dense(1, activation='sigmoid')  # Бинарная классификация\n",
        "])\n",
        "```\n",
        "\n",
        "3. **Компиляция и обучение модели:**\n",
        "\n",
        "```python\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "```\n",
        "\n",
        "4. **Оценка модели:**\n",
        "\n",
        "```python\n",
        "model.evaluate(x_test, y_test)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Использование предобученных моделей\n",
        "\n",
        "TensorFlow позволяет использовать предобученные модели, что значительно ускоряет процесс обучения и улучшает результаты.\n",
        "\n",
        "#### Пример: Использование модели ResNet50 для классификации изображений\n",
        "\n",
        "1. **Импортирование модели:**\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "# Загружаем предобученную модель\n",
        "model = ResNet50(weights='imagenet')\n",
        "```\n",
        "\n",
        "2. **Подготовка изображения:**\n",
        "\n",
        "```python\n",
        "# Загружаем и подготавливаем изображение\n",
        "img_path = 'path_to_image.jpg'  # Путь к изображению\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "```\n",
        "\n",
        "3. **Прогнозирование:**\n",
        "\n",
        "```python\n",
        "preds = model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])  # Выводим три наиболее вероятных класса\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Обработка текстовых данных\n",
        "\n",
        "TensorFlow предоставляет мощные инструменты для обработки и анализа текстов, включая векторизацию слов, создание эмбеддингов и работу с последовательностями.\n",
        "\n",
        "#### Пример: Создание модели для анализа тональности текста\n",
        "\n",
        "1. **Подготовка данных:**\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# Загружаем набор данных IMDB\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Паддинг последовательностей\n",
        "x_train = pad_sequences(x_train, maxlen=500)\n",
        "x_test = pad_sequences(x_test, maxlen=500)\n",
        "```\n",
        "\n",
        "2. **Создание модели:**\n",
        "\n",
        "```python\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(input_dim=10000, output_dim=128, input_length=500),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Бинарная классификация\n",
        "])\n",
        "```\n",
        "\n",
        "3. **Компиляция и обучение модели:**\n",
        "\n",
        "```python\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "```\n",
        "\n",
        "4. **Оценка модели:**\n",
        "\n",
        "```python\n",
        "model.evaluate(x_test, y_test)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Оптимизация и настройка гиперпараметров\n",
        "\n",
        "Оптимизация гиперпараметров является важной частью разработки моделей. TensorFlow предлагает инструменты для автоматизации этого процесса.\n",
        "\n",
        "#### Использование Keras Tuner\n",
        "\n",
        "Keras Tuner позволяет находить лучшие гиперпараметры для вашей модели.\n",
        "\n",
        "```python\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "def build_model(hp):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(hp.Int('units', 32, 512, step=32), activation='relu', input_shape=(784,)))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "tuner = RandomSearch(build_model,\n",
        "                     objective='val_accuracy',\n",
        "                     max_trials=5,\n",
        "                     executions_per_trial=3)\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "```\n",
        "\n",
        "В этом примере мы создаем модель и используем RandomSearch для поиска лучших значений для количества нейронов в скрытом слое.\n",
        "\n",
        "\n",
        "\n",
        "### Вывод\n",
        "\n",
        "TensorFlow — это мощная библиотека, предоставляющая широкий набор инструментов для создания, обучения и развертывания моделей машинного обучения. В этой лекции мы рассмотрели основы TensorFlow, как работать с тензорами, автоматическую дифференциацию, а также как использовать Keras для создания моделей.\n",
        "\n"
      ],
      "metadata": {
        "id": "mxd-FO9mzh-0"
      }
    }
  ]
}